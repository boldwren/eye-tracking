{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "Shape = Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "import cv2\n",
    "from matplotlib import pyplot\n",
    "import tqdm.notebook\n",
    "import ipywidgets as wg\n",
    "import IPython.core.display\n",
    "\n",
    "HOME = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this is broken then patch $VIRTUAL_ENV/lib/python3.7/site-packages/faced/detector.py\n",
    "# as described in https://github.com/iitzco/faced/issues/27 and then:\n",
    "#     del sys.modules[\"faced.detector\"]\n",
    "#     del sys.modules[\"faced\"]\n",
    "# so that it reloads when you import it again.\n",
    "import faced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(predictor_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1000_000)\n",
    "def detect(filename) -> List[Shape]:\n",
    "    img = dlib.load_rgb_image(filename)\n",
    "    dets = detector(img, 1)\n",
    "    shapes = []\n",
    "    for d in dets:\n",
    "        shape = predictor(img, d)\n",
    "        shapes.append(shape)\n",
    "    return shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "face_detector = faced.FaceDetector()\n",
    "\n",
    "def to_rectangles(bboxes):\n",
    "    rectangles = dlib.rectangles()\n",
    "    for (x_center, y_center, width, height, prob) in bboxes:\n",
    "        rectangle = dlib.rectangle(\n",
    "            x_center - (width//2),\n",
    "            y_center - (height//2),\n",
    "            x_center + (width//2),\n",
    "            y_center + (height//2),\n",
    "        )\n",
    "        rectangles.append(rectangle)\n",
    "    return rectangles\n",
    "\n",
    "@lru_cache(maxsize=1000_000)\n",
    "def detect_both_ways(filename):\n",
    "    img = dlib.load_rgb_image(filename)\n",
    "    dets = detector(img, 1)\n",
    "\n",
    "    img = cv2.imread(filename)\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Receives RGB numpy image (HxWxC) and\n",
    "    # returns (x_center, y_center, width, height, prob) tuples. \n",
    "    bboxes = face_detector.predict(rgb_img)\n",
    "    return dets, to_rectangles(bboxes)\n",
    "\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1000_000)\n",
    "def detect2(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    bboxes = face_detector.predict(rgb_img)\n",
    "    rectangles = to_rectangles(bboxes)\n",
    "    faces = []\n",
    "    for d in rectangles:\n",
    "        face = predictor(img, d)\n",
    "        if valid(face, img.shape):\n",
    "            faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    conf_threshold = 0.7\n",
    "    \n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "\n",
    "@lru_cache()\n",
    "def initOpenCVDnn():\n",
    "    modelFile = \"learnopencv/FaceDetectionComparison/models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "    configFile = \"learnopencv/FaceDetectionComparison/models/deploy.prototxt\"\n",
    "    net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    \n",
    "    return net\n",
    "  \n",
    "@lru_cache(maxsize=1000_000)\n",
    "def detect_dnn(filename):\n",
    "    net = initOpenCVDnn()\n",
    "    img = cv2.imread(filename)\n",
    "#     rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,img)\n",
    "    \n",
    "    rectangles = dlib.rectangles()\n",
    "    for bbox in bboxes:\n",
    "        rectangles.append(dlib.rectangle(*bbox))\n",
    "\n",
    "    faces = []\n",
    "    for d in rectangles:\n",
    "        face = predictor(img, d)\n",
    "        if valid(face, img.shape):\n",
    "            faces.append(face)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(face, shape=(1920, 3840, 3)):\n",
    "    y, x, *_channels = shape\n",
    "    return any((point.x < x and point.y < y) for point in face.parts())\n",
    "\n",
    "def only_valid(faces):\n",
    "    return [\n",
    "        face for face in faces\n",
    "        if valid(face)\n",
    "    ]\n",
    "\n",
    "def only_invalid(faces):\n",
    "    return [\n",
    "        face for face in faces\n",
    "        if not valid(face)\n",
    "    ]\n",
    "def detect_with_fallbacks(filename):\n",
    "    return detect_dnn(filename) or detect2(filename) # or detect(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACIAL_LANDMARKS_IDXS = dict([\n",
    "    (\"mouth\", (48, 68)),\n",
    "    (\"right_eyebrow\", (17, 22)),\n",
    "    (\"left_eyebrow\", (22, 27)),\n",
    "    (\"right_eye\", (36, 42)),\n",
    "    (\"left_eye\", (42, 48)),\n",
    "    (\"nose\", (27, 35)),\n",
    "    (\"jaw\", (0, 17))\n",
    "])\n",
    "\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A =  dlib.length(eye[1] - eye[5])\n",
    "    B =  dlib.length(eye[2] - eye[4])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dlib.length(eye[0] - eye[3])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ratio = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ratio\n",
    "\n",
    "def max_eye_aspect_ratio(faces):\n",
    "    max_ratio = 0\n",
    "    for face in faces:\n",
    "        for part in (\"left_eye\", \"right_eye\"):\n",
    "            start, end = FACIAL_LANDMARKS_IDXS[part]\n",
    "            eye = face.parts()[start:end]\n",
    "            ratio = eye_aspect_ratio(eye)\n",
    "            max_ratio = max([ratio, max_ratio])\n",
    "    return max_ratio\n",
    "\n",
    "def eye_score_for_file(filename):\n",
    "    return max_eye_aspect_ratio(detect_with_fallbacks(filename))\n",
    "\n",
    "def max_face_size(faces):\n",
    "    max_size = 0\n",
    "    for face in faces:\n",
    "        parts = face.parts()\n",
    "        size = 0\n",
    "        size += dlib.length(parts[1] - parts[17])\n",
    "        size += dlib.length(parts[2] - parts[16])\n",
    "        size += dlib.length(parts[3] - parts[15])\n",
    "        max_size = max([size, max_size])\n",
    "    return max_size\n",
    "\n",
    "def face_score_for_file(filename):\n",
    "    return max_face_size(detect_with_fallbacks(filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1000_000)\n",
    "def save_face_chip(filename):\n",
    "    faces = detect_with_fallbacks(filename)\n",
    "    scores = [max_eye_aspect_ratio([face]) for face in faces]\n",
    "    if len(faces):\n",
    "        best_face = max(zip(scores, enumerate(faces)))[-1][-1]\n",
    "        img = dlib.load_rgb_image(filename)\n",
    "        dlib.save_face_chip(img, best_face, filename.replace('.jpeg', '.detected'))\n",
    "        return filename.replace('.jpeg', '.detected.jpg')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1000_000)\n",
    "def save_broken_face_chip(filename):\n",
    "    faces = only_invalid(detect_with_fallbacks(filename))\n",
    "    scores = [max_eye_aspect_ratio([face]) for face in faces]\n",
    "    if len(faces):\n",
    "        best_face = max(zip(scores, enumerate(faces)))[-1][-1]\n",
    "        img = dlib.load_rgb_image(filename)\n",
    "        dlib.save_face_chip(img, best_face, filename.replace('.jpeg', '.funky'))\n",
    "        return filename.replace('.jpeg', '.funky.jpg')\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa9c9dd5f814a0cbcea963051cfbb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3156.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "faces_folder_path = f'{HOME}/tmp/*x*/*.mp4.images/'\n",
    "\n",
    "files = list(\n",
    "    f for f in sorted(glob.glob(os.path.join(faces_folder_path, \"*.jpeg\")))\n",
    "    if '/tmp/3840x1920/1.mp4' not in f\n",
    "#     and '1920x1080/1080P_4000K_236777331.mp4' in f\n",
    ")\n",
    "\n",
    "for filename in tqdm.notebook.tqdm(files): #[126:][:1]:\n",
    "#     print(\"Processing file: {}\".format(filename))\n",
    "    shapes = detect_with_fallbacks(filename)\n",
    "    if len(shapes):\n",
    "#         print(len(shapes), max_eye_aspect_ratio(shapes))\n",
    "        continue\n",
    "        save_face_chip(filename)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da27c426335b4bfeb96916a33bb4a31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='x', max=175, min=1), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "face_filenames = list(\n",
    "    sorted(\n",
    "        [\n",
    "            filename for filename in files\n",
    "            if True\n",
    "#             and eye_score_for_file(filename) > 0.25 \n",
    "            and '1920x1080/1080P_4000K_236777331.mp4' in filename\n",
    "#             and only_invalid(detect_with_fallbacks(filename))\n",
    "        ],\n",
    "#         key=face_score_for_file,\n",
    "    )\n",
    ")\n",
    "\n",
    "def show_face(x):\n",
    "    filename = face_filenames[x]\n",
    "    facename = filename.replace('.jpeg', '.detected')\n",
    "    shapes = detect_with_fallbacks(filename)\n",
    "    print(len(shapes), len(detect(filename)), filename.replace(HOME, '~'))\n",
    "    print(eye_score_for_file(filename))\n",
    "    print(face_score_for_file(filename))\n",
    "    \n",
    "    if len(shapes):\n",
    "        filename = save_face_chip(filename)\n",
    "    widget = IPython.core.display.Image(filename=filename)\n",
    "    return widget\n",
    "\n",
    "maxf = len(face_filenames) - 1\n",
    "wg.interact(show_face, x=wg.IntSlider(min=1,max=maxf,step=1));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 3156)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_filenames) , len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 3156)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_filenames) , len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 3156)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_filenames) , len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "totals_breakdown = Counter(filename.split('keyframe')[0] for filename in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_breakdown = Counter(filename.split('keyframe')[0] for filename in face_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = sorted([(faces_breakdown[k]/totals_breakdown[k], k.replace('.images/', '.hls/out.m3u8')) for k in totals_breakdown.keys()], reverse=True)\n",
    "# best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/tmp/1920x1080/1080P_4000K_236777331.mp4.hls/filtered.m3u8\n",
      "~/tmp/3840x1920/5.mp4.hls/filtered.m3u8\n",
      "~/tmp/3840x1920/4.mp4.hls/filtered.m3u8\n",
      "~/tmp/3840x1920/2.mp4.hls/filtered.m3u8\n",
      "~/tmp/2880x1440/1440P_6000K_250245261.mp4.hls/filtered.m3u8\n",
      "~/tmp/2160x1080/3.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_269637061.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_245709591.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_244920861.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_243830341.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_243742671.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_235951531.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_233248671.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_213777192.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_202141221.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_192776321.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_172091701.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_133429751.mp4.hls/filtered.m3u8\n",
      "~/tmp/1920x1080/1080P_4000K_104015132.mp4.hls/filtered.m3u8\n",
      "~/tmp/1280x720/720P_4000K_197919961.mp4.hls/filtered.m3u8\n",
      "~/tmp/1280x720/720P_4000K_128231391.mp4.hls/filtered.m3u8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def to_keyframe_filename(ts_filename):\n",
    "    return ts_filename.replace(\n",
    "        'segment', 'keyframe'\n",
    "    ).replace(\n",
    "        '.ts\\n', '.jpeg'\n",
    "    )\n",
    "\n",
    "def make_filtered_playlist(original_playlist_filename, filter_function):\n",
    "    out = []\n",
    "    chunks: Tuple[str, str] = []\n",
    "    chunk_start: Optional[str] = None\n",
    "    with open(original_playlist_filename) as f:\n",
    "    \n",
    "        lines = iter(f)\n",
    "        for line in lines:\n",
    "            if line.startswith('#EXTINF'):\n",
    "                chunk_start = line\n",
    "                break\n",
    "            out.append(line)\n",
    "\n",
    "        for line in lines:\n",
    "            if chunk_start is not None:\n",
    "                chunks.append((chunk_start, line))\n",
    "                chunk_start = None\n",
    "            elif line.startswith('#EXTINF'):\n",
    "                chunk_start = line\n",
    "            else:\n",
    "                # really I should use a peekable iterator, or put line back on\n",
    "                # the front of lines, but nevermind.\n",
    "                trailing_line = line\n",
    "                break\n",
    "        else:\n",
    "            trailing_line = ''\n",
    "\n",
    "        chunks = [\n",
    "            chunk\n",
    "            for chunk in chunks\n",
    "            if filter_function(\n",
    "                original_playlist_filename.replace(\n",
    "                    '.hls/out.m3u8', \n",
    "                    '.images/' + to_keyframe_filename(chunk[-1])\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        for chunk in chunks:\n",
    "            out.extend(chunk)\n",
    "            # Credit to @DHE in #ffmpeg on freenode for suggesting\n",
    "            # #EXT-X-DISCONTINUITY.\n",
    "            # https://developer.apple.com/documentation/http_live_streaming/example_playlists_for_http_live_streaming/incorporating_ads_into_a_playlist\n",
    "            out.append('#EXT-X-DISCONTINUITY\\n')\n",
    "        # strip the #EXT-X-DISCONTINUITY from after the last chunk\n",
    "        out.pop()\n",
    "        out.append(trailing_line)\n",
    "\n",
    "        for line in lines:\n",
    "            out.append(line)\n",
    "\n",
    "    filtered_filename = original_playlist_filename.replace('out.m3u8', 'filtered.m3u8')\n",
    "    with open(filtered_filename,'w',) as f:\n",
    "        f.write(''.join(out)+'\\n')\n",
    "    return filtered_filename.replace(HOME, '~')\n",
    "        \n",
    "\n",
    "def has_eye_contact(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        return False\n",
    "    return eye_score_for_file(filename) > 0.25\n",
    "\n",
    "for _score, filename in best:\n",
    "    print(make_filtered_playlist(\n",
    "        filename,\n",
    "        has_eye_contact,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = [\n",
    "    (filename, face)\n",
    "    for filename in files\n",
    "        if ('1920x1080/1080P_4000K_236777331.mp4' in filename)\n",
    "            for face in only_invalid(detect_with_fallbacks(filename))\n",
    "#                 if not any((point.x < 1920 and point.y < 1080) for point in face.parts())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1399c0c90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.figure()\n",
    "for filename, face in faces:\n",
    "    points = [\n",
    "        (point.x, -point.y)\n",
    "        for point in face.parts()\n",
    "    ]\n",
    "    pyplot.scatter(*zip(*points), label=filename.replace(HOME, '~'))\n",
    "pyplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
